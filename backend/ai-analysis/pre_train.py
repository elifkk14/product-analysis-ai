import os
import re
import json
import time

import requests
import ollama
import pandas as pd
import logging
import psutil
from typing import List, Dict, Any
from pydantic import BaseModel, field_validator, ValidationError
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
from concurrent.futures import ThreadPoolExecutor

# ------------------------------
# Configuration
# ------------------------------
load_dotenv()
logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(asctime)s - %(message)s")

class Config:
    INPUT_PATH = os.getenv("INPUT_PATH", "./data/")
    OUTPUT_PATH = os.getenv("OUTPUT_PATH", "./results/")
    RISK_WEIGHTS = {
        "High": 4,
        "Medium": 2,
        "Low": 1,
        "Carcinogenic": 3,
        "Endocrine Disruptor": 2,
        "Allergen": 1
    }
    @classmethod
    def validate_paths(cls):
        """Dizinleri oluÅŸtur ve izinleri kontrol et"""
        try:
            # GiriÅŸ dizini kontrolÃ¼
            if not os.path.exists(cls.INPUT_PATH):
                logging.warning(f"âš ï¸ Input dizini yok: {cls.INPUT_PATH}")
                os.makedirs(cls.INPUT_PATH, exist_ok=True)
                
            # Ã‡Ä±kÄ±ÅŸ dizini oluÅŸturma
            os.makedirs(cls.OUTPUT_PATH, exist_ok=True)
            
            # Yazma izni kontrolÃ¼
            if not os.access(cls.OUTPUT_PATH, os.W_OK):
                raise PermissionError(f"âœ–ï¸ Yazma izni yok: {cls.OUTPUT_PATH}")
                
            logging.info(f"ğŸ“‚ Dizinler hazÄ±r: INPUT={cls.INPUT_PATH} OUTPUT={cls.OUTPUT_PATH}")
            
        except Exception as e:
            logging.critical(f"âŒ Dizin hatasÄ±: {str(e)}")
            raise

    @classmethod
    def get_batch_size(cls) -> int:
        """Dinamik batch boyutu belirleme"""
        free_mem = psutil.virtual_memory().available // (1024 ** 3)  # GB cinsinden
        return max(1, free_mem // 2)

    @classmethod
    def get_max_workers(cls) -> int:
        """Sistem kaynaklarÄ±na gÃ¶re thread sayÄ±sÄ±"""
        return min(4, (os.cpu_count() or 1) // 2)

    @classmethod
    def load_substances(cls) -> Dict[str, Any]:
        """Madde verilerini yÃ¼kleme"""
        base_path = os.getenv("DATA_PATH", "./data/")
        
        try:
            df_harmful = pd.read_parquet(os.path.join(base_path, "harmful_substances.parquet"))
            df_safe = pd.read_parquet(os.path.join(base_path, "safe_substances.parquet"))
            
            df_harmful = df_harmful.drop_duplicates(subset=["substance"])
            df_safe["description"] = df_safe.get("description", "No description available")
            
            return {
                'harmful': df_harmful.set_index("substance")[["category", "reason", "severity"]].to_dict(orient='index'),
                'safe': df_safe.set_index("substance")["description"].to_dict()
            }
        except Exception as e:
            logging.critical(f"Substance data loading failed: {str(e)}")
            raise

# ------------------------------
# Ollama Integration
# ------------------------------
class SafetyAnalyzer:
    @staticmethod
    def analyze_ingredients(ingredients: List[str]) -> Dict[str, Any]:
        """Ollama API ile iÃ§erik analizi yapar ve yanÄ±tÄ± doÄŸrular."""
        try:
            # Net talimatlarla Ä°ngilizce prompt
            response = ollama.generate(
                model="mistral:latest",
                prompt=f"""SYSTEM ROLE: You are a chemical safety expert. Return STRICT JSON ONLY.

                ANALYSIS REQUEST: Analyze these cosmetic ingredients for health risks:
                {json.dumps(ingredients)}

                RESPONSE FORMAT:
                {{
                "harmful_ingredients": [{{"name": "chemical_name", "description": "health risk reason"}}],
                "safe_ingredients": ["safe_ingredient_name"],
                "description": "max 50 word summary"
                }}

                INSTRUCTIONS:
                1. Analyze ONLY the provided ingredients
                2. Never add explanations
                3. Use scientific terminology
                4. Output MUST be valid JSON without formatting issues""",
                                stream=False,
                                format="json"
                            )

            raw_response = response.get('response', '').strip()
            logging.info(f"ğŸ“„ Raw Response:\n{raw_response}")

            # GeliÅŸtirilmiÅŸ JSON Ã§Ä±karÄ±mÄ±
            json_match = re.search(
                r"(?:```json\s*)?({.*})\s*(?:```)?",
                raw_response,
                re.DOTALL
            )
            
            if json_match:
                clean_json = json_match.group(1)
                # JSON temizleme
                clean_json = re.sub(r'[\x00-\x1F]+', '', clean_json)  # Control karakterleri kaldÄ±r
                parsed_response = json.loads(clean_json)
            else:
                try:
                    parsed_response = json.loads(raw_response)
                except json.JSONDecodeError:
                    return {"error": "Invalid JSON format"}

            # KatÄ± validasyon
            if not SafetyAnalyzer._validate_response(parsed_response):
                logging.error("ğŸš¨ Validation failed for response")
                return {"error": "Response validation failed"}

            return parsed_response

        except Exception as e:
            logging.error(f"âŒ Critical Error: {str(e)}")
            return {"error": str(e)}

    @staticmethod
    def _validate_response(response: Dict) -> bool:
        """YanÄ±tÄ±n yapÄ±sÄ±nÄ± kontrol eder"""
        required_keys = {
            "harmful_ingredients": list,
            "safe_ingredients": list,
            "description": str
        }
        
        # Anahtar varlÄ±k kontrolÃ¼
        if not all(key in response for key in required_keys):
            logging.error(f"Missing keys: {required_keys - response.keys()}")
            return False
            
        # Veri tipi kontrolÃ¼
        type_checks = [
            (isinstance(response['harmful_ingredients'], list)),
            (isinstance(response['safe_ingredients'], list)),
            (isinstance(response['description'], str))
        ]
        if not all(type_checks):
            logging.error("Type mismatch in response")
            return False
            
        # ZararlÄ± iÃ§eriklerin yapÄ±sÄ±
        for item in response['harmful_ingredients']:
            if not all(k in item for k in ("name", "description")):
                logging.error("Invalid harmful_ingredients structure")
                return False
                
        return True

    @staticmethod
    def _parse_response(raw_text: str, attempt: int) -> Dict[str, Any]:
        """YanÄ±t JSON formatÄ±nda deÄŸilse, ham metinden JSON Ã§Ä±karmaya Ã§alÄ±ÅŸÄ±r."""
        try:
            # JSON kod bloÄŸu varsa temizle
            json_match = re.search(r"(?:```json\s*)?(\{.*\})\s*(?:```)?", raw_text, re.DOTALL)
            clean_json = json_match.group(1) if json_match else raw_text

            # JSON olarak parse et
            parsed_response = json.loads(clean_json)

            # JSON'da anahtarlarÄ±n olup olmadÄ±ÄŸÄ±nÄ± kontrol et
            required_keys = {"harmful_ingredients", "safe_ingredients", "description"}
            missing_keys = required_keys - parsed_response.keys()

            if missing_keys:
                logging.warning(f"âš ï¸ JSON yanÄ±tÄ±nda eksik anahtarlar var: {missing_keys}")

            return parsed_response

        except (AttributeError, json.JSONDecodeError, ValueError) as e:
            logging.warning(f"âš ï¸ YanÄ±t JSON formatÄ±nda deÄŸil, fallback stratejisi uygulanÄ±yor. Hata: {e}")

            # Fallback: Ã–nemli kelimeleri yakalayan bir regex ile yanÄ±t Ã¼ret
            harmful = list(set(re.findall(
                r'\b(paraben|sulfate|phthalate|fragrance|triclosan)\b',
                raw_text,
                flags=re.IGNORECASE
            )))

            return {
                "harmful_ingredients": [{"name": item, "description": "Detected as potentially harmful"} for item in harmful],
                "safe_ingredients": [],
                "description": "Automatic keyword-based risk analysis",
            }

# ------------------------------
# Data Processing
# ------------------------------
class DataProcessor:
    @staticmethod
    def sanitize_text(text: str) -> str:
        """GÃ¼venli metin temizleme"""
        return re.sub(r"[^a-zA-Z0-9\s,.-]", "", str(text))[:500]

    @staticmethod
    def parse_ingredients(text: str) -> List[str]:
        """Daha kapsamlÄ± iÃ§erik ayrÄ±ÅŸtÄ±rma"""
        text = re.sub(r"(?i)\b(and|or|with|contains?|ingredients?)\b", ",", text)
        return sorted({
            re.sub(r"\s+", " ", ing.strip())
            for ing in re.split(r"[\n,;:+&|/]", text)
            if len(ing.strip()) > 2 and not ing.strip().isdigit()
        })

    @staticmethod
    def calculate_risk(harmful: List[str], substances: dict) -> str:
        """Risk seviyesi hesaplama"""
        if not harmful:
            return "Low"
        
        score = sum(
            Config.RISK_WEIGHTS.get(substances['harmful'].get(ing, {}).get("severity", "Low"), 0) +
            Config.RISK_WEIGHTS.get(substances['harmful'].get(ing, {}).get("category", "Other"), 0)
            for ing in harmful
        )
        return "Very High" if score >= 10 else "High" if score >=7 else "Medium" if score >=4 else "Low"

# ------------------------------
# Pipeline
# ------------------------------
class AnalysisPipeline:
    def __init__(self):
        self.substances = Config.load_substances()

    def process(self, df: pd.DataFrame) -> pd.DataFrame:
        """Ana iÅŸlem akÄ±ÅŸÄ±"""
        # Ã–n iÅŸlemler
        df = self._preprocess(df)
        
        # Batch iÅŸleme
        results = []
        batches = self._create_batches(df)
        
        with ThreadPoolExecutor(max_workers=Config.get_max_workers()) as executor:
            futures = [executor.submit(self.process_batch, batch) for batch in batches]
            
            for future in as_completed(futures):
                try:
                    results.append(future.result())
                except Exception as e:
                    logging.error(f"Batch processing failed: {str(e)}")
                    results.append(pd.DataFrame())

        # SonuÃ§larÄ± birleÅŸtir
        return self._combine_results(df, pd.concat(results))

    def _preprocess(self, df: pd.DataFrame) -> pd.DataFrame:
        """Veriyi hazÄ±rlama"""
        df = df.dropna(subset=['barcode', 'name']).copy()
        df['ingredients'] = df['ingredients'].fillna('').apply(DataProcessor.parse_ingredients)
        return df

    def _create_batches(self, df: pd.DataFrame) -> List[pd.DataFrame]:
        """Dinamik batch oluÅŸturma"""
        batch_size = Config.get_batch_size()
        return [df.iloc[i:i+batch_size] for i in range(0, len(df), batch_size)]

    def process_batch(self, batch: pd.DataFrame) -> pd.DataFrame:
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(SafetyAnalyzer.analyze_ingredients, ingredients) 
                    for ingredients in batch['ingredients']]
            analyses = [f.result() for f in futures]
        return self._format_results(batch, analyses)

    def _format_results(self, batch: pd.DataFrame, analyses: List[dict]) -> pd.DataFrame:
        """SonuÃ§larÄ± formatlama"""
        result = batch.copy()
        # Her Ã¼rÃ¼n iÃ§in ayrÄ± analiz
        result['harmful_ingredients'] = [a.get('harmful_ingredients', []) for a in analyses]
        result['safe_ingredients'] = [a.get('safe_ingredients', []) for a in analyses]
        result['description'] = [a.get('description', '') for a in analyses]
        
        return result

    def _combine_results(self, original: pd.DataFrame, processed: pd.DataFrame) -> pd.DataFrame:
        """SonuÃ§larÄ± birleÅŸtirme"""
        return original.merge(
            processed[['barcode', 'harmful_ingredients', 'safe_ingredients', 'description', 'risk_level']],
            on='barcode',
            how='left'
        )
    
# ------------------------------
# Model Kontrol FonksiyonlarÄ± (Yeni Eklenen)
# ------------------------------
def check_ollama_connection() -> bool:
    """Ollama servisinin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrular"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        return response.status_code == 200
    except Exception as e:
        logging.error(f"Ollama connection failed: {str(e)}")
        return False

def verify_model() -> bool:
    """DoÄŸru modelin yÃ¼klÃ¼ olduÄŸunu kontrol eder"""
    try:
        models = ollama.list().get('models', [])
        
        logging.info("Mevcut Modeller:")
        for model in models:
            # Model bilgilerini doÄŸru anahtarla al
            model_name = model.get('model', 'UNKNOWN')
            logging.info(f"- {model_name}")

        # Model isimlerinde 'mistral' ara (bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarsÄ±z)
        return any('mistral' in model.get('model', '').lower() for model in models)
    except Exception as e:
        logging.error(f"Model doÄŸrulama hatasÄ±: {str(e)}")
        return False

# ------------------------------
# Execution
# ------------------------------
def main():
    try:
        # Test
        test_data = pd.DataFrame({
            'barcode': ['TEST123', 'TEST456'],
            'name': ['Test Product 1', 'Test Product 2'],
            'ingredients': [
                'water, sodium lauryl sulfate, parabens',
                'organic coconut oil, vitamin E'
            ]
        })
        
        pipeline = AnalysisPipeline()
        test_result = pipeline.process(test_data)
        logging.info("Test results:\n%s", test_result)
        
        # Ana iÅŸlem
        input_file = os.path.join(Config.INPUT_PATH, "/Users/konak/Downloads/product-analysis/backend/ai-analysis/data/processed_openfoodfacts.parquet")
        output_file = os.path.join(Config.OUTPUT_PATH, "pre_train_results.csv")
        
        df = pd.read_parquet(input_file)
        result = pipeline.process(df)
        
        os.makedirs(Config.OUTPUT_PATH, exist_ok=True)
        result.to_csv(output_file, index=False)
        logging.info("Analysis completed. Results saved to: %s", output_file)
        
    except Exception as e:
        logging.critical("Pipeline execution failed: %s", str(e), exc_info=True)
        raise



# ------------------------------
# Main Execution (GÃ¼ncellenmiÅŸ)
# ------------------------------
if __name__ == "__main__":
    try:
        # 1. Ollama baÄŸlantÄ± ve model kontrolleri
        logging.info("ğŸ” Sistem kontrolleri baÅŸlatÄ±lÄ±yor...")
        
        if not check_ollama_connection():
            logging.critical("âŒ Ollama servisi Ã§alÄ±ÅŸmÄ±yor! 'ollama serve' komutu ile baÅŸlatÄ±n.")
            exit(1)
            
        if not verify_model():
            logging.critical("âŒ Mistral modeli yÃ¼klÃ¼ deÄŸil! Komut: 'ollama pull mistral'")
            exit(1)

        # 2. Test analizi
        logging.info("ğŸ§ª Test analizi baÅŸlatÄ±lÄ±yor...")
        test_ingredients = ["water", "sodium lauryl sulfate", "parabens"]
        test_result = SafetyAnalyzer.analyze_ingredients(test_ingredients)
        
        if "error" in test_result:
            logging.error("âŒ Test baÅŸarÄ±sÄ±z! Ã–rnek yanÄ±t:")
            print(json.dumps(test_result, indent=2))
            exit(1)
            
        # 3. Ana iÅŸlem
        logging.info("ğŸš€ Ana analiz baÅŸlatÄ±lÄ±yor...")
        
        # Yol kontrolleri
        Config.validate_paths()
        input_path = os.path.abspath(os.path.join(Config.INPUT_PATH, "/Users/konak/Downloads/product-analysis/backend/ai-analysis/data/processed_openfoodfacts.parquet"))
        output_path = os.path.abspath(os.path.join(Config.OUTPUT_PATH, "pre_train_results.csv"))
        
        # Veriyi yÃ¼kle ve iÅŸle
        df = pd.read_parquet(input_path)
        pipeline = AnalysisPipeline()
        result = pipeline.process(df)
        
        # SonuÃ§larÄ± kaydet
        result.to_csv(output_path, index=False)
        logging.info(f"âœ… BaÅŸarÄ±yla kaydedildi: {output_path}")
        print(f"\nğŸ“‚ Ã‡Ä±ktÄ± Dosya Yolu:\n{output_path}")

    except Exception as e:
        logging.critical(f"â›” Kritik hata: {str(e)}", exc_info=True)
        print("\nğŸ†˜ Ã‡Ã¶zÃ¼m adÄ±mlarÄ±:")
        print("1. Ollama servisinin Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun: 'ollama serve'")
        print("2. Dosya izinlerini kontrol edin: 'chmod 755 ./results'")
        print("3. Input dosyasÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± doÄŸrulayÄ±n")
        exit(1)

